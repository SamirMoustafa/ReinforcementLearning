{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Asterix-ram-v0')\n",
    "n_episodes = 100\n",
    "max_step = 2000\n",
    "eps = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "policy_net = nn.Sequential(\n",
    "                    #nn.Linear(128, 128),\n",
    "                    #nn.LeakyReLU(0.01),\n",
    "                    nn.Linear(128, 64),\n",
    "                    nn.LeakyReLU(0.01),\n",
    "                    nn.Linear(64, 9),\n",
    "                    nn.Softmax()\n",
    "                    )\n",
    "policy_net.to(device)\n",
    "policy_optimizer = torch.optim.Adam(policy_net.parameters(), lr=3e-3)\n",
    "policy_scheduler = torch.optim.lr_scheduler.StepLR(policy_optimizer, 5, gamma=0.95)\n",
    "\n",
    "value_net = nn.Sequential(\n",
    "                    #nn.Linear(128, 128),\n",
    "                    #nn.LeakyReLU(0.01),\n",
    "                    nn.Linear(128, 64),\n",
    "                    nn.LeakyReLU(0.01),\n",
    "                    nn.Linear(64, 1)\n",
    "                    )\n",
    "value_net.to(device)\n",
    "value_optimizer = torch.optim.Adam(value_net.parameters(), lr=3e-3)\n",
    "value_scheduler = torch.optim.lr_scheduler.StepLR(value_optimizer, 5, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards = []\n",
    "freq = max(n_episodes // 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0/100 || Reward: 50.0  Steps: 293\n",
      "log grad: tensor(319.3661, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-698.2320], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 5/100 || Reward: 200.0  Steps: 757\n",
      "log grad: tensor(0.0198, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([2129123.5000], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 10/100 || Reward: 200.0  Steps: 768\n",
      "log grad: tensor(0.0307, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([3717976.], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 15/100 || Reward: 200.0  Steps: 762\n",
      "log grad: tensor(0.0167, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([1648764.5000], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 20/100 || Reward: 200.0  Steps: 761\n",
      "log grad: tensor(-0.0057, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-510225.4688], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 25/100 || Reward: 200.0  Steps: 772\n",
      "log grad: tensor(-0.0133, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-929115.3750], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 30/100 || Reward: 200.0  Steps: 762\n",
      "log grad: tensor(-0.0048, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-527692.4375], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 35/100 || Reward: 200.0  Steps: 771\n",
      "log grad: tensor(0.0054, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([275074.4688], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 40/100 || Reward: 200.0  Steps: 764\n",
      "log grad: tensor(0.0050, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([214060.6875], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 45/100 || Reward: 200.0  Steps: 759\n",
      "log grad: tensor(-0.0026, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-447713.9062], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 50/100 || Reward: 200.0  Steps: 750\n",
      "log grad: tensor(-0.0042, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-577790.3125], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 55/100 || Reward: 200.0  Steps: 762\n",
      "log grad: tensor(0.0013, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-197496.0156], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 60/100 || Reward: 200.0  Steps: 753\n",
      "log grad: tensor(0.0014, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-194119.2031], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 65/100 || Reward: 200.0  Steps: 766\n",
      "log grad: tensor(-0.0023, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-488235.2812], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 70/100 || Reward: 200.0  Steps: 762\n",
      "log grad: tensor(-1.0539e-05, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-327686.5625], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 75/100 || Reward: 200.0  Steps: 762\n",
      "log grad: tensor(0.0003, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-292382.0625], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 80/100 || Reward: 200.0  Steps: 754\n",
      "log grad: tensor(-0.0009, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-387239.1562], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 85/100 || Reward: 200.0  Steps: 751\n",
      "log grad: tensor(-0.0005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-354582.4688], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 90/100 || Reward: 200.0  Steps: 768\n",
      "log grad: tensor(-0.0005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-337905.0625], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n",
      "Episode: 95/100 || Reward: 200.0  Steps: 756\n",
      "log grad: tensor(-0.0007, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "value grad tensor([-333581.7812], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for episode in range(n_episodes):\n",
    "    logs = []\n",
    "    rewards = []\n",
    "    values = []\n",
    "    state = torch.tensor(env.reset(), dtype=torch.float32).to(device)\n",
    "    for step in range(max_step):\n",
    "        policy = policy_net(state)\n",
    "        action = np.random.choice(np.arange(9), p=policy.cpu().detach().numpy())\n",
    "        log = torch.log(policy[action] + 1e-6)\n",
    "        #print(log)\n",
    "        logs.append(log)\n",
    "        value = value_net(state)\n",
    "        values.append(value)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        state = torch.tensor(state, dtype=torch.float32).to(device)\n",
    "        \n",
    "        rewards.append(reward)\n",
    "        if done:\n",
    "            break\n",
    "    T = len(rewards)\n",
    "    #print(rewards[-1])\n",
    "    rewards = np.array(rewards)\n",
    "    total_rewards.append(rewards.sum())\n",
    "    \n",
    "    G = []\n",
    "    for t in range(T):\n",
    "        g = rewards[t:].sum() - values[t].cpu().detach().numpy()[0]\n",
    "        G.append(g)\n",
    "        \n",
    "    log_grads = 0\n",
    "    for log, g in zip(logs, G):\n",
    "        log_grads -= g * log\n",
    "        \n",
    "    value_grads = 0\n",
    "    for value, g in zip(values, G):\n",
    "        value_grads -= g * value\n",
    "    \n",
    "    policy_optimizer.zero_grad()\n",
    "    log_grads.to(device).backward(retain_graph=True)\n",
    "    policy_optimizer.step()\n",
    "    policy_scheduler.step()\n",
    "    \n",
    "    value_optimizer.zero_grad()\n",
    "    value_grads.to(device).backward()\n",
    "    value_optimizer.step()\n",
    "    value_scheduler.step()\n",
    "    \n",
    "    if not episode % freq:\n",
    "        print('Episode: {}/{} || Reward: {}  Steps: {}'.format(episode, n_episodes, total_rewards[-1], T))\n",
    "        print('log grad:', log_grads)\n",
    "        print('value grad', value_grads, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fce87c41da0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
